# Awesome Papers about Direct-trained Spiking Neural Network (SNN) in Various Fields ⭐️

## Description
This repository is an up-to-date list of significant papers about Direct-trained Spiking Neural Network (SNN) in various fields. 
Feel free to give this repository a star if you enjoy the work.

## Table of Contents

- [Review](#review)
- [Image classification](#Image-classification)
- [Obect detection](#Object-detection)
- [Image segmentation](#Image-segmentation)
- [Object tracking](#Object-tracking)
- [Object recognition](#Object-recognition)



## Review <a name="review"></a>

* ⭐️ 2024: Direct training high-performance deep spiking neural networks: a review of theories and methods. [paper] [code]
  
* ⭐️ 2020: Rethinking the performance comparison between SNNs and ANNs. [paper] [code]

* ⭐️ 2020: Comparing SNNs and RNNs on neuromorphic vision datasets: similarities and differences. [paper] [code]

## Image classification <a name="Image-classification"></a>

### CNN-based SNN

* ⭐️ 2024: SpikingResformer: bridging resnet and vision transformer in spiking neural networks. [paper] [code]

* ⭐️ 2021: MS-ResNet: Advancing spiking neural networks toward deep residual learning. [paper] [code]

* ⭐️ 2021: SEW-ResNet: deep residual learning in spiking neural networks. [paper] [code]

* ⭐️ 2020: Spiking deep residual network. [paper] [code]

* ⭐️ 2020: Going deeper with directly-trained larger spiking neural network. [paper] [code]

* ⭐️ 2019: Direct training for spiking neural networks: faster, larger, better. [paper] [code]

* ⭐️ 2018: Spatio-temporal backpropagation for training high-performance spiking neural networks. [paper] [code]

### Attention-based SNN

* ⭐️ 2022: Attention spiking neural networks. [paper] [code]
  
* ⭐️ 2021: Temporal-wise attention spiking neural networks for event streams classification. [paper] [code]

### Transformer-based SNN

* ⭐️ 2024: SpikingResformer: bridging resnet and vision transformer in spiking neural networks. [paper] [code]

* ⭐️ 2024: QKFormer: hierarchical spiking transformer using Q-K attention. [paper] [code]

* ⭐️ 2024: Spike-drive transformer v2: meta spiking neural network architecture inspiring the design of next-generation neuromorphic chips. [paper] [code]

* ⭐️ 2023: Spike-driven transformer. [paper] [code]
  
* ⭐️ 2023: Spikingformer: spike-driven residual learning for transformer-based spiking neural network. [paper] [code]
  
* ⭐️ 2022: Spikformer: when spiking neural network meets transformer. [paper] [code]



## Object detection <a name="Object-detection"></a>

* ⭐️ 2024: SFOD: spiking fusion object detector. [paper] [code]

* ⭐️ 2024: Spike-drive transformer v2: meta spiking neural network architecture inspiring the design of next-generation neuromorphic chips. [paper] [code]

* ⭐️ 2024: Integer-valued training and spike-driven inference spiking neural network for high-performance and energy-efficient object objection. [paper] [code]

* ⭐️ 2023: EMS-Yolo: deep directly-trained spiking neural networks for object detection. [paper] [code]



## Image segmentation <a name="Image-segmentation"></a>

* ⭐️ 2024: Spike-drive transformer v2: meta spiking neural network architecture inspiring the design of next-generation neuromorphic chips. [paper] [code]

* ⭐️ 2021: A spiking neural network for image segmentation. [paper] [code]

* ⭐️ 2020: SpikeSED: spiking segmentation via STDP slaiency mapping. [paper](https://strathprints.strath.ac.uk/72071/1/Kirkland_etal_IJCNN_2020_SpikeSEG_spiking_segmentation_via_STDP.pdf) [code]



## Object tracking <a name="Object-tracking"></a>

* ⭐️ 2022: Spiking transformers for event-based single object tracking. [paper] [code]

* ⭐️ 2022: Spiking SiamFC++: deep spiking neural network for objecting. [paper] [code]

* ⭐️ 2021: SiamSNN: siamese spiking neural networks for energy-efficient object tracking. [paper] [code]
  
* ⭐️ 2019: DashNet: a hybrid artificial and spiking neural network for high-speed object tracking. [paper] [code]


## Object recognition  <a name="Object-recognition"></a>

* ⭐️ 2024: Shrinking Your TimeStep: towards low-latency neuromorphic object recognition with spiking neural networks. [paper] [code]



